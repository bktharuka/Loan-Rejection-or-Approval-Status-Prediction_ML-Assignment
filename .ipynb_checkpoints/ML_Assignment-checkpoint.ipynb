{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b04be50-69a1-4f01-a794-cd226e0d68c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Necessary Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1167ad2b-8982-44f5-af78-e982eb0eb8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and assign data set\n",
    "df = pd.read_csv('loan_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fa12b8-6930-4c85-9ca1-f994450ce23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check about first 5 data rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c452691e-4e29-46b5-b20b-a34fc2302652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check about null data columns\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f1e66c-b8ed-483f-848a-aba56c219461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the summary of how data sacattered\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b49291-ed1b-4fdc-b95c-5e5e01851241",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Generating Histograms\n",
    "df.hist(figsize=(12,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0581eb8d-b882-4cac-806f-29a29f74bb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating box plot\n",
    "sns.boxplot(x='Loan_Status', y='ApplicantIncome', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3798064-f17c-4410-be8b-110dae9bb4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate counter plot\n",
    "sns.countplot(x='Education', hue='Loan_Status', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d634aa44-cd25-483a-9adf-2a55ffaf319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################*************  DATA PREPROCESSING ************########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c076424e-d7b2-4ed6-8363-03b807f88f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns that not much effect to the predictions.\n",
    "columns_to_drop = ['Unnamed: 0', 'Loan_ID']\n",
    "df_1 = df.drop(columns=columns_to_drop, inplace=False)\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfa1c9d-0413-4514-aace-a24d4896a95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting Count Of Missing Values In Each Column\n",
    "df_1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68272910-136e-476e-b0df-fce466582f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill the numerical value columns null data points with mean to avoid null values\n",
    "numerical_cols_to_fill = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']\n",
    "df_1[numerical_cols_to_fill] = df_1[numerical_cols_to_fill].fillna(df[numerical_cols_to_fill].mean())\n",
    "df_1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d8cb82-d4e1-4e2d-936a-278c301ea89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the categorical value columns data rows that containing null values for avoid null data points\n",
    "columns_to_check = ['Gender','Dependents','Education', 'Self_Employed', 'Credit_History']\n",
    "df_1.dropna(subset=columns_to_check, inplace=True)\n",
    "df_1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8417ef12-fa00-45a1-9c8a-d705a31fc9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the size of data set after cleaning null values\n",
    "df_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6ef2da-adcb-453c-9a91-7484a19e8b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting categerical variables to numerical values using Label Encorder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "categorical_cols_to_label_encode = ['Gender', 'Married','Dependents' , 'Education','Self_Employed','Property_Area','Loan_Status']\n",
    "\n",
    "for col in categorical_cols_to_label_encode:\n",
    "    df_1[col] = label_encoder.fit_transform(df_1[col])\n",
    "\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a072b9de-682a-4896-bf17-a945778da650",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating Corelation Mtrix ForLatest Data Set\n",
    "correlation_matrix = df_1.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "threshold = 0.8\n",
    "\n",
    "high_correlation = (correlation_matrix.abs() > threshold) & (correlation_matrix.abs() < 1.0)\n",
    "high_correlation_pairs = [(correlation_matrix.columns[i], correlation_matrix.columns[j]) for i in range(len(high_correlation.columns)) for j in range(i+1, len(high_correlation.columns)) if high_correlation.iloc[i, j]]\n",
    "\n",
    "print(\"Highly correlated column pairs:\", high_correlation_pairs)  # Debugging print\n",
    "if len(high_correlation_pairs) == 0:\n",
    "    print(\"There are no highly correlated column pairs.\")\n",
    "else:\n",
    "    print(\"Highly correlated column pairs:\")\n",
    "    for pair in high_correlation_pairs:\n",
    "        print(f\"{pair[0]} - {pair[1]}: {correlation_matrix.loc[pair[0], pair[1]]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8f6a1a-d067-4032-a239-9570fb514b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#By using robust scaler scale data point to between one range\n",
    "scaler = RobustScaler()\n",
    "numerical_features = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Property_Area']\n",
    "df_1[numerical_features] = scaler.fit_transform(df_1[numerical_features])\n",
    "print(df_1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3917878-b684-4b01-8bb4-869cbb112dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset to  train and test\n",
    "X = df_1.drop('Loan_Status', axis=1)  # Features\n",
    "y = df_1['Loan_Status']  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_features = X_train.shape[(1)]\n",
    "train_size = X_test.shape[(0)]\n",
    "test_features = X_test.shape[(1)]\n",
    "test_size = X_test.shape[(0)]\n",
    "\n",
    "print(\"Number Of Features In Test Set :\", train_features)\n",
    "print(\"Size of Train set:\", train_size)\n",
    "print(\"Number Of Features In Train Set :\", test_features)\n",
    "print(\"Size of Test set:\", test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2520cfce-c727-4fd0-a365-282f70af98f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "             #############************----------- Training The Models -----------************#############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030cfcf2-6d7c-4a2a-9781-acff27d42737",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################----LOGISTIC REGRESSION----######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4d98db-f2ad-4405-bbdf-4a2d88820788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train THe Data Set Using Logistic Regression Algorithm\n",
    "params = {\n",
    "    'C': 1,                   # Regularization parameter\n",
    "    'penalty': 'l1',            # Regularization penalty ('l1' for Lasso, 'l2' for Ridge)\n",
    "    'solver': 'liblinear',      # Algorithm to use in the optimization problem\n",
    "    'max_iter': 100             # Maximum number of iterations for optimization\n",
    "}\n",
    "logistic_regression = LogisticRegression(**params)\n",
    "logistic_regression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf574ff8-97e2-48f6-a877-eeff4d51f6cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Gettin Prediction And Get Evaluate Matrics\n",
    "y_pred = logistic_regression.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, logistic_regression.predict_proba(X_test)[:, 1])  # Use predicted probabilities for ROC-AUC\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28378b3-1220-4361-90d8-6df42b2e22c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot confusion matrix for Logistic Regresssion model\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, cmap='Blues', annot=True, fmt='d')\n",
    "for i in range(len(conf_matrix)):\n",
    "    for j in range(len(conf_matrix)):\n",
    "        plt.text(j+0.5, i+0.5, conf_matrix[i, j], ha='center', va='center', color='black', fontsize=10)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Logistic Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b4eef7-a377-4e79-ab55-adc316598d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Grid search cv optimize the Logistic Regression Hyper Parameters\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter': [200, 500, 1000]\n",
    "}\n",
    "grid_search = GridSearchCV(logistic_regression, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff166c5-e865-4c59-a819-bb5e999e788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Evaluation Matrix For best Parameters.\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e460848-2ab7-41d0-814c-0c50e35b2bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################----DECISION TREE----######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c70004-1f45-40bd-85ae-de721b0d3857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train The Data Set Using Decision Treee Classifier \n",
    "decision_tree = DecisionTreeClassifier(max_depth=5, min_samples_split=2, min_samples_leaf=1)\n",
    "\n",
    "# Train the decision tree classifier on the training data\n",
    "decision_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a5f453-fedb-4de5-9d6d-aae61c775f68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting Predictions And Evaluation Matrics for Decision Tree Classifier Model\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889d959b-66e3-42fe-9790-1d19941568a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for Decission Tree Classifier Model\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        plt.text(j, i, str(conf_matrix[i, j]), horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.xticks([0, 1], ['Rejected', 'Approved'])\n",
    "plt.yticks([0, 1], ['Rejected', 'Approved'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e666d33e-cdb3-4a82-bd09-914a7c7ad22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize decision tree for the model\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(decision_tree, filled=True, feature_names=X.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3956ace-80cc-4206-80f8-86ef125de8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checkoin for optimize decission tree hyper parameters\n",
    "param_grid = {\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(decision_tree, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51a1291-a8c2-48b2-ad3b-4c26392bfa58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466588f6-dbe3-431a-8463-b9166f85926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################----RANDOM FOREST----######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7110f04b-25d5-4bf6-9939-51ca9361ecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset using random forest algorithm\n",
    "random_forest = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
    "\n",
    "random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011c0d92-b726-4d87-b2e8-431929ce94eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting Predictions and Evaluation Matrics\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82d4cb4-a29e-40a7-99df-682c7227dfc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix \n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        plt.text(j, i, str(conf_matrix[i, j]), horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "classes = ['Rejected', 'Approved']\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes)\n",
    "plt.yticks(tick_marks, classes)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049e7bbb-02cd-4f70-8ae4-e95b0d155d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check For Best Hyper Parameters To The Random Forest Algorithm  \n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(random_forest, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a618ba7-daba-4092-b5a4-9e64a44ab95a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca695ca-63bc-41ea-adc5-3dbc757e944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################----SUPPORT VECTOR MACHINE (SVM)----######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edf2762-72c5-4b49-afe0-c8bffcd5311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Model Using Support vector Machine\n",
    "svm_classifier = SVC(kernel='linear', C=0.1, gamma='scale')\n",
    "\n",
    "svm_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce27152d-db51-40ef-9adf-8ff7eecbb65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting Predictions and Evaluation Matrics for Support Vector Machine\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c42df4d-3cc3-4529-989d-7cd957eaf676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Conussion Matrix For  Support Vector Machine\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        plt.text(j, i, str(conf_matrix[i, j]), horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "classes = ['Rejected', 'Approved']\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes)\n",
    "plt.yticks(tick_marks, classes)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02122ff-8140-49fd-8f3e-28a6ed452576",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check For Best Hyper Parameters To The Support Vector Machine\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "svm_classifier = SVC()\n",
    "\n",
    "grid_search = GridSearchCV(svm_classifier, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b92d1ea-5451-463a-a56d-d4b99d9ff135",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
